diff --git a/examples/src/main/java/org/apache/ignite/examples/ml/sql/DecisionTreeClassificationTrainerSQLInferenceExample.java b/examples/src/main/java/org/apache/ignite/examples/ml/sql/DecisionTreeClassificationTrainerSQLInferenceExample.java
index 02e15f6d69de7..ab2a00c2721bd 100644
--- a/examples/src/main/java/org/apache/ignite/examples/ml/sql/DecisionTreeClassificationTrainerSQLInferenceExample.java
+++ b/examples/src/main/java/org/apache/ignite/examples/ml/sql/DecisionTreeClassificationTrainerSQLInferenceExample.java
@@ -17,13 +17,17 @@
 
 package org.apache.ignite.examples.ml.sql;
 
+import java.util.HashSet;
 import java.util.List;
 import org.apache.ignite.Ignite;
 import org.apache.ignite.IgniteCache;
+import org.apache.ignite.IgniteCheckedException;
 import org.apache.ignite.Ignition;
 import org.apache.ignite.cache.query.QueryCursor;
 import org.apache.ignite.cache.query.SqlFieldsQuery;
 import org.apache.ignite.configuration.CacheConfiguration;
+import org.apache.ignite.internal.IgniteEx;
+import org.apache.ignite.internal.processors.query.h2.IgniteH2Indexing;
 import org.apache.ignite.internal.util.IgniteUtils;
 import org.apache.ignite.ml.dataset.feature.extractor.impl.BinaryObjectVectorizer;
 import org.apache.ignite.ml.inference.IgniteModelStorageUtil;
@@ -55,13 +59,18 @@ public class DecisionTreeClassificationTrainerSQLInferenceExample {
     /**
      * Run example.
      */
-    public static void main(String[] args) {
+    public static void main(String[] args) throws IgniteCheckedException {
         System.out.println(">>> Decision tree classification trainer example started.");
 
         // Start ignite grid.
         try (Ignite ignite = Ignition.start("examples/config/example-ignite-ml.xml")) {
             System.out.println(">>> Ignite grid started.");
 
+            // Use internal API to enable SQL functions disabled by default (the function CSVREAD is used below)
+            // TODO: IGNITE-12903
+            ((IgniteH2Indexing)((IgniteEx)ignite).context().query().getIndexing())
+                .distributedConfiguration().disabledFunctions(new HashSet<>());
+
             // Dummy cache is required to perform SQL queries.
             CacheConfiguration<?, ?> cacheCfg = new CacheConfiguration<>(DUMMY_CACHE_NAME)
                 .setSqlSchema("PUBLIC")
diff --git a/examples/src/main/java/org/apache/ignite/examples/ml/sql/DecisionTreeClassificationTrainerSQLTableExample.java b/examples/src/main/java/org/apache/ignite/examples/ml/sql/DecisionTreeClassificationTrainerSQLTableExample.java
index dff2977756f38..5fe123c8366cb 100644
--- a/examples/src/main/java/org/apache/ignite/examples/ml/sql/DecisionTreeClassificationTrainerSQLTableExample.java
+++ b/examples/src/main/java/org/apache/ignite/examples/ml/sql/DecisionTreeClassificationTrainerSQLTableExample.java
@@ -17,13 +17,17 @@
 
 package org.apache.ignite.examples.ml.sql;
 
+import java.util.HashSet;
 import java.util.List;
 import org.apache.ignite.Ignite;
 import org.apache.ignite.IgniteCache;
+import org.apache.ignite.IgniteCheckedException;
 import org.apache.ignite.Ignition;
 import org.apache.ignite.cache.query.QueryCursor;
 import org.apache.ignite.cache.query.SqlFieldsQuery;
 import org.apache.ignite.configuration.CacheConfiguration;
+import org.apache.ignite.internal.IgniteEx;
+import org.apache.ignite.internal.processors.query.h2.IgniteH2Indexing;
 import org.apache.ignite.internal.util.IgniteUtils;
 import org.apache.ignite.ml.dataset.feature.extractor.impl.BinaryObjectVectorizer;
 import org.apache.ignite.ml.math.primitives.vector.Vector;
@@ -54,13 +58,18 @@ public class DecisionTreeClassificationTrainerSQLTableExample {
     /**
      * Run example.
      */
-    public static void main(String[] args) {
+    public static void main(String[] args) throws IgniteCheckedException {
         System.out.println(">>> Decision tree classification trainer example started.");
 
         // Start ignite grid.
         try (Ignite ignite = Ignition.start("examples/config/example-ignite.xml")) {
             System.out.println(">>> Ignite grid started.");
 
+            // Use internal API to enable SQL functions disabled by default (the function CSVREAD is used below)
+            // TODO: IGNITE-12903
+            ((IgniteH2Indexing)((IgniteEx)ignite).context().query().getIndexing())
+                .distributedConfiguration().disabledFunctions(new HashSet<>());
+
             // Dummy cache is required to perform SQL queries.
             CacheConfiguration<?, ?> cacheCfg = new CacheConfiguration<>(DUMMY_CACHE_NAME)
                 .setSqlSchema("PUBLIC");
diff --git a/modules/clients/src/test/java/org/apache/ignite/jdbc/thin/JdbcThinBatchSelfTest.java b/modules/clients/src/test/java/org/apache/ignite/jdbc/thin/JdbcThinBatchSelfTest.java
index 377bd885d6b90..c5aebfb29acea 100644
--- a/modules/clients/src/test/java/org/apache/ignite/jdbc/thin/JdbcThinBatchSelfTest.java
+++ b/modules/clients/src/test/java/org/apache/ignite/jdbc/thin/JdbcThinBatchSelfTest.java
@@ -180,8 +180,6 @@ public void testBatchException() throws Exception {
             fail("BatchUpdateException must be thrown");
         }
         catch (BatchUpdateException e) {
-            checkThereAreNotUsedConnections();
-
             int[] updCnts = e.getUpdateCounts();
 
             assertEquals("Invalid update counts size", BATCH_SIZE, updCnts.length);
@@ -226,8 +224,6 @@ public void testBatchParseException() throws Exception {
             fail("BatchUpdateException must be thrown");
         }
         catch (BatchUpdateException e) {
-            checkThereAreNotUsedConnections();
-
             int[] updCnts = e.getUpdateCounts();
 
             assertEquals("Invalid update counts size", BATCH_SIZE, updCnts.length);
@@ -292,8 +288,6 @@ public void testBatchMergeParseException() throws Exception {
             fail("BatchUpdateException must be thrown");
         }
         catch (BatchUpdateException e) {
-            checkThereAreNotUsedConnections();
-
             int[] updCnts = e.getUpdateCounts();
 
             assertEquals("Invalid update counts size", BATCH_SIZE, updCnts.length);
@@ -340,8 +334,6 @@ public void testBatchKeyDuplicatesException() throws Exception {
             fail("BatchUpdateException must be thrown");
         }
         catch (BatchUpdateException e) {
-            checkThereAreNotUsedConnections();
-
             int[] updCnts = e.getUpdateCounts();
 
             assertEquals("Invalid update counts size", BATCH_SIZE, updCnts.length);
@@ -398,8 +390,6 @@ public void testHeterogeneousBatchException() throws Exception {
             fail("BatchUpdateException must be thrown");
         }
         catch (BatchUpdateException e) {
-            checkThereAreNotUsedConnections();
-
             int[] updCnts = e.getUpdateCounts();
 
             if (!e.getMessage().contains("Value conversion failed")) {
@@ -551,8 +541,6 @@ public void testBatchExceptionPrepared() throws Exception {
             fail("BatchUpdateException must be thrown");
         }
         catch (BatchUpdateException e) {
-            checkThereAreNotUsedConnections();
-
             int[] updCnts = e.getUpdateCounts();
 
             assertEquals("Invalid update counts size", BATCH_SIZE, updCnts.length);
@@ -651,8 +639,6 @@ public void testBatchMergeExceptionPrepared() throws Exception {
             fail("BatchUpdateException must be thrown res=" + Arrays.toString(res));
         }
         catch (BatchUpdateException e) {
-            checkThereAreNotUsedConnections();
-
             int[] updCnts = e.getUpdateCounts();
 
             assertEquals("Invalid update counts size", BATCH_SIZE, updCnts.length);
@@ -744,8 +730,6 @@ public void testBatchUpdateExceptionPrepared() throws Exception {
             fail("BatchUpdateException must be thrown res=" + Arrays.toString(res));
         }
         catch (BatchUpdateException e) {
-            checkThereAreNotUsedConnections();
-
             int[] updCnts = e.getUpdateCounts();
 
             assertEquals("Invalid update counts size", BATCH_SIZE, updCnts.length);
@@ -829,8 +813,6 @@ public void testBatchDeleteExceptionPrepared() throws Exception {
             fail("BatchUpdateException must be thrown res=" + Arrays.toString(res));
         }
         catch (BatchUpdateException e) {
-            checkThereAreNotUsedConnections();
-
             int[] updCnts = e.getUpdateCounts();
 
             assertEquals("Invalid update counts size", BATCH_SIZE, updCnts.length);
diff --git a/modules/core/src/main/java/org/apache/ignite/internal/cluster/DistributedBaselineConfiguration.java b/modules/core/src/main/java/org/apache/ignite/internal/cluster/DistributedBaselineConfiguration.java
index a27e582373e51..aa0a97893b176 100644
--- a/modules/core/src/main/java/org/apache/ignite/internal/cluster/DistributedBaselineConfiguration.java
+++ b/modules/core/src/main/java/org/apache/ignite/internal/cluster/DistributedBaselineConfiguration.java
@@ -17,24 +17,19 @@
 
 package org.apache.ignite.internal.cluster;
 
-import java.io.Serializable;
-import java.util.Objects;
 import org.apache.ignite.IgniteCheckedException;
 import org.apache.ignite.IgniteLogger;
 import org.apache.ignite.internal.GridKernalContext;
-import org.apache.ignite.internal.IgniteInternalFuture;
-import org.apache.ignite.internal.processors.configuration.distributed.DistributePropertyListener;
 import org.apache.ignite.internal.processors.configuration.distributed.DistributedChangeableProperty;
 import org.apache.ignite.internal.processors.configuration.distributed.DistributedConfigurationLifecycleListener;
-import org.apache.ignite.internal.processors.configuration.distributed.DistributedProperty;
 import org.apache.ignite.internal.processors.configuration.distributed.DistributedPropertyDispatcher;
 import org.apache.ignite.internal.processors.subscription.GridInternalSubscriptionProcessor;
 import org.apache.ignite.internal.util.future.GridFutureAdapter;
 import org.apache.ignite.internal.util.typedef.internal.CU;
-import org.apache.ignite.lang.IgniteInClosure;
-import org.jetbrains.annotations.NotNull;
 
 import static java.lang.String.format;
+import static org.apache.ignite.internal.cluster.DistributedConfigurationUtils.makeUpdateListener;
+import static org.apache.ignite.internal.cluster.DistributedConfigurationUtils.setDefaultValue;
 import static org.apache.ignite.internal.processors.configuration.distributed.DistributedBooleanProperty.detachedBooleanProperty;
 import static org.apache.ignite.internal.processors.configuration.distributed.DistributedLongProperty.detachedLongProperty;
 
@@ -92,8 +87,8 @@ public DistributedBaselineConfiguration(
         isp.registerDistributedConfigurationListener(
             new DistributedConfigurationLifecycleListener() {
                 @Override public void onReadyToRegister(DistributedPropertyDispatcher dispatcher) {
-                    baselineAutoAdjustEnabled.addListener(makeUpdateListener());
-                    baselineAutoAdjustTimeout.addListener(makeUpdateListener());
+                    baselineAutoAdjustEnabled.addListener(makeUpdateListener(PROPERTY_UPDATE_MESSAGE, log));
+                    baselineAutoAdjustTimeout.addListener(makeUpdateListener(PROPERTY_UPDATE_MESSAGE, log));
 
                     dispatcher.registerProperties(baselineAutoAdjustEnabled, baselineAutoAdjustTimeout);
                 }
@@ -106,38 +101,6 @@ public DistributedBaselineConfiguration(
         );
     }
 
-    /**
-     * @param property Property which value should be set.
-     * @param value Default value.
-     * @param log Logger.
-     * @param <T> Property type.
-     */
-    private <T extends Serializable> void setDefaultValue(DistributedProperty<T> property, T value, IgniteLogger log) {
-        if (property.get() == null) {
-            try {
-                property.propagateAsync(null, value)
-                    .listen((IgniteInClosure<IgniteInternalFuture<?>>)future -> {
-                        if (future.error() != null)
-                            log.error("Cannot set default value of '" + property.getName() + '\'', future.error());
-                    });
-            }
-            catch (IgniteCheckedException e) {
-                log.error("Cannot initiate setting default value of '" + property.getName() + '\'', e);
-            }
-        }
-    }
-
-    /**
-     * @param <T> Type of property value.
-     * @return Update property listener.
-     */
-    @NotNull private <T> DistributePropertyListener<T> makeUpdateListener() {
-        return (name, oldVal, newVal) -> {
-            if (!Objects.equals(oldVal, newVal))
-                log.info(format(PROPERTY_UPDATE_MESSAGE, name, oldVal, newVal));
-        };
-    }
-
     /**
      * Called when cluster performing activation.
      */
diff --git a/modules/core/src/main/java/org/apache/ignite/internal/cluster/DistributedConfigurationUtils.java b/modules/core/src/main/java/org/apache/ignite/internal/cluster/DistributedConfigurationUtils.java
new file mode 100644
index 0000000000000..f3fe31bf3f859
--- /dev/null
+++ b/modules/core/src/main/java/org/apache/ignite/internal/cluster/DistributedConfigurationUtils.java
@@ -0,0 +1,77 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.ignite.internal.cluster;
+
+import java.io.Serializable;
+import java.util.Objects;
+import org.apache.ignite.IgniteCheckedException;
+import org.apache.ignite.IgniteLogger;
+import org.apache.ignite.internal.IgniteInternalFuture;
+import org.apache.ignite.internal.processors.configuration.distributed.DistributePropertyListener;
+import org.apache.ignite.internal.processors.configuration.distributed.DistributedProperty;
+import org.apache.ignite.lang.IgniteInClosure;
+import org.jetbrains.annotations.NotNull;
+
+import static java.lang.String.format;
+
+/**
+ * Distributed configuration utilities methods.
+ */
+public final class DistributedConfigurationUtils {
+    /**
+     */
+    private DistributedConfigurationUtils() {
+        // No-op.
+    }
+
+    /**
+     * @param property Property which value should be set.
+     * @param value Default value.
+     * @param log Logger.
+     * @param <T> Property type.
+     */
+    public static <T extends Serializable> void setDefaultValue(DistributedProperty<T> property, T value, IgniteLogger log) {
+        if (property.get() == null) {
+            try {
+                property.propagateAsync(null, value)
+                    .listen((IgniteInClosure<IgniteInternalFuture<?>>)future -> {
+                        if (future.error() != null)
+                            log.error("Cannot set default value of '" + property.getName() + '\'', future.error());
+                    });
+            }
+            catch (IgniteCheckedException e) {
+                log.error("Cannot initiate setting default value of '" + property.getName() + '\'', e);
+            }
+        }
+    }
+
+    /**
+     * @param propUpdMsg Update message.
+     * @param log Logger.
+     * @param <T> Type of property value.
+     * @return Update property listener.
+     */
+    @NotNull public static <T> DistributePropertyListener<T> makeUpdateListener(String propUpdMsg, IgniteLogger log) {
+        return (name, oldVal, newVal) -> {
+            if (!Objects.equals(oldVal, newVal)) {
+                if (log.isInfoEnabled())
+                    log.info(format(propUpdMsg, name, oldVal, newVal));
+            }
+        };
+    }
+}
diff --git a/modules/core/src/test/java/org/apache/ignite/internal/processors/metastorage/DistributedMetaStorageTest.java b/modules/core/src/test/java/org/apache/ignite/internal/processors/metastorage/DistributedMetaStorageTest.java
index 97616fb3e37ba..09a0825f542a6 100644
--- a/modules/core/src/test/java/org/apache/ignite/internal/processors/metastorage/DistributedMetaStorageTest.java
+++ b/modules/core/src/test/java/org/apache/ignite/internal/processors/metastorage/DistributedMetaStorageTest.java
@@ -52,7 +52,20 @@ public class DistributedMetaStorageTest extends GridCommonAbstractTest {
      * Used in tests for updatesCount counter of metastorage and corresponds to keys BASELINE_ENABLED and other initial
      * objects that were added but should not be counted along with keys defined in tests.
      */
-    private static final int INITIAL_UPDATES_COUNT = 2;
+    private static int initialUpdatesCount = -1;
+
+    /** {@inheritDoc} */
+    @Override protected void beforeTestsStarted() throws Exception {
+        super.beforeTestsStarted();
+
+        startGrid(0);
+
+        // We have to start the second node and wait when it is started
+        // to be sure that all async metastorage updates of the node_0 are completed.
+        startGrid(1);
+
+        initialUpdatesCount = (int)metastorage(0).getUpdatesCount();
+    }
 
     /** {@inheritDoc} */
     @Override protected IgniteConfiguration getConfiguration(String igniteInstanceName) throws Exception {
@@ -333,18 +346,17 @@ public void testOptimizedWriteTwice() throws Exception {
 
         metastorage(0).write("key1", "value1");
 
-        assertEquals(1, metastorage(0).getUpdatesCount() - INITIAL_UPDATES_COUNT);
+        assertEquals(1, metastorage(0).getUpdatesCount() - initialUpdatesCount);
 
         metastorage(0).write("key2", "value2");
 
-        assertEquals(2, metastorage(0).getUpdatesCount() - INITIAL_UPDATES_COUNT);
+        assertEquals(2, metastorage(0).getUpdatesCount() - initialUpdatesCount);
 
         metastorage(0).write("key1", "value1");
 
-        assertEquals(2, metastorage(0).getUpdatesCount() - INITIAL_UPDATES_COUNT);
+        assertEquals(2, metastorage(0).getUpdatesCount() - initialUpdatesCount);
     }
 
-    /** */
     /** */
     @Test
     public void testClient() throws Exception {
@@ -358,7 +370,7 @@ public void testClient() throws Exception {
 
         AtomicInteger clientLsnrUpdatesCnt = new AtomicInteger();
 
-        assertEquals(1, metastorage(1).getUpdatesCount() - INITIAL_UPDATES_COUNT);
+        assertEquals(1, metastorage(1).getUpdatesCount() - initialUpdatesCount);
 
         assertEquals("value0", metastorage(1).read("key0"));
 
@@ -400,7 +412,7 @@ public void testClientReconnect() throws Exception {
 
         // Wait enough to cover failover timeout.
         assertTrue(GridTestUtils.waitForCondition(
-            () -> metastorage(1).getUpdatesCount() - INITIAL_UPDATES_COUNT == expUpdatesCnt, 15_000));
+            () -> metastorage(1).getUpdatesCount() - initialUpdatesCount == expUpdatesCnt, 15_000));
 
         if (isPersistent())
             assertEquals("value0", metastorage(1).read("key0"));
diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/DistributedSqlConfiguration.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/DistributedSqlConfiguration.java
new file mode 100644
index 0000000000000..442aed7e991b0
--- /dev/null
+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/DistributedSqlConfiguration.java
@@ -0,0 +1,120 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.ignite.internal.processors.query.h2;
+
+import java.util.Arrays;
+import java.util.HashSet;
+import java.util.Set;
+import java.util.stream.Collectors;
+import org.apache.ignite.IgniteCheckedException;
+import org.apache.ignite.IgniteLogger;
+import org.apache.ignite.internal.GridKernalContext;
+import org.apache.ignite.internal.processors.configuration.distributed.DistributePropertyListener;
+import org.apache.ignite.internal.processors.configuration.distributed.DistributedConfigurationLifecycleListener;
+import org.apache.ignite.internal.processors.configuration.distributed.DistributedPropertyDispatcher;
+import org.apache.ignite.internal.processors.configuration.distributed.SimpleDistributedProperty;
+import org.apache.ignite.internal.processors.metastorage.ReadableDistributedMetaStorage;
+import org.apache.ignite.internal.util.future.GridFutureAdapter;
+
+import static org.apache.ignite.internal.cluster.DistributedConfigurationUtils.makeUpdateListener;
+import static org.apache.ignite.internal.cluster.DistributedConfigurationUtils.setDefaultValue;
+
+/**
+ * Distributed configuration of the indexing module.
+ */
+public class DistributedSqlConfiguration {
+    /** Property update message. */
+    private static final String PROPERTY_UPDATE_MESSAGE =
+        "SQL parameter '%s' was changed from '%s' to '%s'";
+
+    /** Default disabled SQL functions. */
+    public static final HashSet<String> DFLT_DISABLED_FUNCS = (HashSet<String>)Arrays.stream(new String[] {
+        "FILE_READ",
+        "FILE_WRITE",
+        "CSVWRITE",
+        "CSVREAD",
+        "MEMORY_FREE",
+        "MEMORY_USED",
+        "LOCK_MODE",
+        "LINK_SCHEMA",
+        "SESSION_ID",
+        "CANCEL_SESSION"
+    }).collect(Collectors.toSet());
+
+    /** Disabled SQL functions. */
+    private final SimpleDistributedProperty<HashSet<String>> disabledSqlFuncs
+        = new SimpleDistributedProperty<>("sql.disabledFunctions");
+
+    /**
+     * @param ctx Kernal context
+     * @param log Logger.
+     */
+    public DistributedSqlConfiguration(
+        GridKernalContext ctx,
+        IgniteLogger log
+    ) {
+        ctx.internalSubscriptionProcessor().registerDistributedConfigurationListener(
+            new DistributedConfigurationLifecycleListener() {
+                @Override public void onReadyToRegister(DistributedPropertyDispatcher dispatcher) {
+                    disabledSqlFuncs.addListener(makeUpdateListener(PROPERTY_UPDATE_MESSAGE, log));
+
+                    dispatcher.registerProperties(disabledSqlFuncs);
+                }
+
+                @Override public void onReadyToWrite() {
+                    if (ReadableDistributedMetaStorage.isSupported(ctx)) {
+                        setDefaultValue(
+                            disabledSqlFuncs,
+                            DFLT_DISABLED_FUNCS,
+                            log);
+                    }
+                    else {
+                        log.warning("Distributed metastorage is not supported. " +
+                            "All distributed SQL configuration parameters are unavailable.");
+
+                        // Set disabled functions to default.
+                        disabledSqlFuncs.localUpdate(null);
+                    }
+                }
+            }
+        );
+    }
+
+    /**
+     * @return Disabled SQL functions.
+     */
+    public Set<String> disabledFunctions() {
+        Set<String> ret = disabledSqlFuncs.get();
+
+        return ret != null ? ret : DFLT_DISABLED_FUNCS;
+    }
+
+    /**
+     * @param disabledFuncs Set of disabled functions.
+     * @throws IgniteCheckedException if failed.
+     */
+    public GridFutureAdapter<?> disabledFunctions(HashSet<String> disabledFuncs)
+        throws IgniteCheckedException {
+        return disabledSqlFuncs.propagateAsync(disabledFuncs);
+    }
+
+    /** */
+    public void listenDisabledFunctions(DistributePropertyListener<HashSet<String>> lsnr) {
+        disabledSqlFuncs.addListener(lsnr);
+    }
+}
diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/FunctionsManager.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/FunctionsManager.java
new file mode 100644
index 0000000000000..fae51039cc78b
--- /dev/null
+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/FunctionsManager.java
@@ -0,0 +1,88 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.ignite.internal.processors.query.h2;
+
+import java.lang.reflect.Field;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Objects;
+import java.util.Set;
+import org.h2.expression.Function;
+
+/**
+ * SQL function manager.
+ */
+@SuppressWarnings("unchecked")
+public class FunctionsManager {
+    /** Original H2 functions set. */
+    private static HashMap<String, Object> origFuncs;
+
+    /** Current H2 functions set. */
+    private static HashMap<String, Object> funcs;
+
+    static {
+        // Extract from H2 the set of available functions.
+        try {
+            Field fldFUNCTIONS = Function.class.getDeclaredField("FUNCTIONS");
+
+            fldFUNCTIONS.setAccessible(true);
+
+            funcs = (HashMap<String, Object>)fldFUNCTIONS.get(Class.class);
+
+            origFuncs = new HashMap<>(funcs);
+        }
+        catch (NoSuchFieldException | IllegalAccessException e) {
+            e.printStackTrace();
+        }
+    }
+
+    /**
+     *
+     */
+    public FunctionsManager(DistributedSqlConfiguration distSqlCfg) {
+        assert Objects.nonNull(funcs);
+        assert Objects.nonNull(origFuncs);
+        distSqlCfg.listenDisabledFunctions(this::updateDisabledFunctions);
+    }
+
+    /**
+     * Listener of changes the SQL parameter 'disabled functions'.
+     *
+     * @param paramName Parameter name (unused)
+     * @param oldDisabledFuncs Old set of disabled functions.
+     * @param newDisabledFuncs New set of disabled functions.
+     */
+    private void updateDisabledFunctions(
+        String paramName,
+        HashSet<String> oldDisabledFuncs,
+        HashSet<String> newDisabledFuncs) {
+        if (newDisabledFuncs != null)
+            removeFunctions(newDisabledFuncs);
+        else
+            removeFunctions(DistributedSqlConfiguration.DFLT_DISABLED_FUNCS);
+    }
+
+    /**
+     * @param funcNames Set of function that must be removed from original functions set.
+     */
+    private static void removeFunctions(Set<String> funcNames) {
+        funcs.putAll(origFuncs);
+
+        funcs.keySet().removeAll(funcNames);
+    }
+}
diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/IgniteH2Indexing.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/IgniteH2Indexing.java
index 2fa69865fc240..79a43e35e292d 100644
--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/IgniteH2Indexing.java
+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/IgniteH2Indexing.java
@@ -316,6 +316,12 @@ public class IgniteH2Indexing implements GridQueryIndexing {
     /** Query message listener. */
     private GridMessageListener qryLsnr;
 
+    /** Distributed config. */
+    private DistributedSqlConfiguration distrCfg;
+
+    /** Functions manager. */
+    private FunctionsManager funcMgr;
+
     /**
      * @return Kernal context.
      */
@@ -2144,6 +2150,10 @@ public RunningQueryManager runningQueryManager() {
             U.warn(log, "Custom H2 serialization is already configured, will override.");
 
         JdbcUtils.serializer = h2Serializer();
+
+        distrCfg = new DistributedSqlConfiguration(ctx, log);
+
+        funcMgr = new FunctionsManager(distrCfg);
     }
 
     /**
@@ -3100,4 +3110,12 @@ else if (plan.hasRows()) {
     public LongRunningQueryManager longRunningQueries() {
         return longRunningQryMgr;
     }
+
+    /**
+     * @return Distributed SQL configuration.
+     */
+    public DistributedSqlConfiguration distributedConfiguration() {
+        return distrCfg;
+    }
+
 }
diff --git a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/cache/index/H2ConnectionLeaksSelfTest.java b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/cache/index/H2ConnectionLeaksSelfTest.java
index d2fe9ab6b4a98..a14460e3c4702 100644
--- a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/cache/index/H2ConnectionLeaksSelfTest.java
+++ b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/cache/index/H2ConnectionLeaksSelfTest.java
@@ -19,7 +19,6 @@
 
 import java.util.List;
 import java.util.Map;
-import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.CountDownLatch;
 import org.apache.ignite.IgniteCache;
 import org.apache.ignite.IgniteException;
diff --git a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/DisabledSqlFunctionsTest.java b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/DisabledSqlFunctionsTest.java
new file mode 100644
index 0000000000000..ca6192e9c504b
--- /dev/null
+++ b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/DisabledSqlFunctionsTest.java
@@ -0,0 +1,290 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.ignite.internal.processors.query;
+
+import java.nio.file.FileSystem;
+import java.nio.file.FileSystems;
+import java.nio.file.Files;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.LinkedHashSet;
+import java.util.List;
+import java.util.Set;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import java.util.stream.Collectors;
+import org.apache.ignite.IgniteCache;
+import org.apache.ignite.IgniteCheckedException;
+import org.apache.ignite.cache.QueryEntity;
+import org.apache.ignite.cache.affinity.rendezvous.RendezvousAffinityFunction;
+import org.apache.ignite.cache.query.FieldsQueryCursor;
+import org.apache.ignite.cache.query.SqlFieldsQuery;
+import org.apache.ignite.configuration.CacheConfiguration;
+import org.apache.ignite.internal.IgniteEx;
+import org.apache.ignite.internal.processors.cache.index.AbstractIndexingCommonTest;
+import org.apache.ignite.internal.processors.query.h2.IgniteH2Indexing;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.junit.runners.Parameterized;
+
+/**
+ * Tests for disabled SQL functions.
+ */
+@RunWith(Parameterized.class)
+public class DisabledSqlFunctionsTest extends AbstractIndexingCommonTest {
+    /** Pattern func not found. */
+    private static final Pattern PTRN_FUNC_NOT_FOUND = Pattern.compile("Failed to parse query. Function \"\\w+\" not found");
+
+    /** Keys count. */
+    private static final int KEY_CNT = 10;
+
+    /** Local mode. */
+    @Parameterized.Parameter
+    public boolean local;
+
+    /** Executes query on client node. */
+    @Parameterized.Parameter(1)
+    public boolean client;
+
+    /**
+     * @return Test parameters.
+     */
+    @Parameterized.Parameters(name = "local={0}, client={1}")
+    public static Collection parameters() {
+        Set<Object[]> paramsSet = new LinkedHashSet<>();
+
+        for (int i = 0; i < 4; ++i) {
+            Object[] params = new Object[2];
+
+            params[0] = (i & 1) == 0;
+            params[1] = (i & 2) == 0;
+
+            paramsSet.add(params);
+        }
+
+        return paramsSet;
+    }
+
+    /** {@inheritDoc} */
+    @Override protected void afterTest() throws Exception {
+        stopAllGrids();
+
+        FileSystem fs = FileSystems.getDefault();
+
+        Files.deleteIfExists(fs.getPath("test.dat"));
+        Files.deleteIfExists(fs.getPath("test.csv"));
+        Files.deleteIfExists(fs.getPath("test.mv.db"));
+
+        super.afterTest();
+    }
+
+    /** {@inheritDoc} */
+    @Override protected void beforeTest() throws Exception {
+        startGrid("srv");
+        startGrid("cli");
+
+        IgniteCache<Long, Long> c = grid("srv").createCache(new CacheConfiguration<Long, Long>()
+            .setName("test")
+            .setSqlSchema("PUBLIC")
+            .setQueryEntities(Collections.singleton(new QueryEntity(Long.class, Long.class)
+                .setTableName("test")
+                .addQueryField("id", Long.class.getName(), null)
+                .addQueryField("val", Long.class.getName(), null)
+                .setKeyFieldName("id")
+                .setValueFieldName("val")
+            ))
+            .setAffinity(new RendezvousAffinityFunction(false, 10)));
+
+        for (long i = 0; i < KEY_CNT; ++i)
+            c.put(i, i);
+
+    }
+
+    /**
+     */
+    @Test
+    public void testDefaultSelect() throws Exception {
+        checkSqlWithDisabledFunction("SELECT FILE_WRITE(0, 'test.dat')");
+        checkSqlWithDisabledFunction("SELECT FILE_READ('test.dat')");
+        checkSqlWithDisabledFunction("SELECT CSVWRITE('test.csv', 'select 1, 2')");
+        checkSqlWithDisabledFunction("SELECT * FROM CSVREAD('test.csv')");
+        checkSqlWithDisabledFunction("SELECT MEMORY_FREE()");
+        checkSqlWithDisabledFunction("SELECT MEMORY_USED()");
+        checkSqlWithDisabledFunction("SELECT LOCK_MODE()");
+        checkSqlWithDisabledFunction("SELECT LINK_SCHEMA('TEST2', '', 'jdbc:h2:./test', 'sa', 'sa', 'PUBLIC')");
+        checkSqlWithDisabledFunction("SELECT SESSION_ID()");
+        checkSqlWithDisabledFunction("SELECT CANCEL_SESSION(1)");
+    }
+
+    /**
+     */
+    @Test
+    public void testDefaultInsert() throws Exception {
+        checkSqlWithDisabledFunction("INSERT INTO TEST (ID, VAL) SELECT 1, FILE_WRITE(0, 'test.dat')");
+        checkSqlWithDisabledFunction("INSERT INTO TEST (ID, VAL) SELECT 1, FILE_READ('test.dat')");
+        checkSqlWithDisabledFunction("INSERT INTO TEST (ID, VAL) SELECT 1, SELECT CSVWRITE('test.csv', 'select 1, 2')");
+        checkSqlWithDisabledFunction("INSERT INTO TEST (ID, VAL) SELECT 1, count(*) FROM CSVREAD('test.csv')");
+        checkSqlWithDisabledFunction("INSERT INTO TEST (ID, VAL) SELECT 1, MEMORY_FREE()");
+        checkSqlWithDisabledFunction("INSERT INTO TEST (ID, VAL) SELECT 1, MEMORY_USED()");
+        checkSqlWithDisabledFunction("INSERT INTO TEST (ID, VAL) SELECT 1, LOCK_MODE()");
+        checkSqlWithDisabledFunction(
+            "INSERT INTO TEST (ID, VAL) SELECT 1, LINK_SCHEMA('TEST2', '', 'jdbc:h2:./test', 'sa', 'sa', 'PUBLIC')");
+        checkSqlWithDisabledFunction("INSERT INTO TEST (ID, VAL) SELECT 1, SESSION_ID()");
+        checkSqlWithDisabledFunction("INSERT INTO TEST (ID, VAL) SELECT 1, CANCEL_SESSION(1)");
+    }
+
+    /**
+     */
+    @Test
+    public void testDefaultUpdate() throws Exception {
+        checkSqlWithDisabledFunction("UPDATE TEST SET VAL = FILE_WRITE(0, 'test.dat')");
+        checkSqlWithDisabledFunction("UPDATE TEST SET VAL = LENGTH(FILE_READ('test.dat'))");
+        checkSqlWithDisabledFunction("UPDATE TEST SET VAL = CSVWRITE('test.csv', 'select 1, 2')");
+        checkSqlWithDisabledFunction("UPDATE TEST SET VAL = SELECT count(*) FROM CSVREAD('test.csv')");
+        checkSqlWithDisabledFunction("UPDATE TEST SET VAL = MEMORY_FREE()");
+        checkSqlWithDisabledFunction("UPDATE TEST SET VAL = MEMORY_USED()");
+        checkSqlWithDisabledFunction("UPDATE TEST SET VAL = LOCK_MODE()");
+        checkSqlWithDisabledFunction("UPDATE TEST SET VAL = LINK_SCHEMA('TEST2', '', 'jdbc:h2:./test', 'sa', 'sa', 'PUBLIC')");
+        checkSqlWithDisabledFunction("UPDATE TEST SET VAL = SESSION_ID()");
+        checkSqlWithDisabledFunction("UPDATE TEST SET VAL = CANCEL_SESSION(1)");
+    }
+
+    /**
+     */
+    @Test
+    public void testDefaultDelete() throws Exception {
+        checkSqlWithDisabledFunction("DELETE FROM TEST WHERE VAL = FILE_WRITE(0, 'test.dat')");
+        checkSqlWithDisabledFunction("DELETE FROM TEST WHERE VAL = LENGTH(FILE_READ('test.dat'))");
+        checkSqlWithDisabledFunction("DELETE FROM TEST WHERE VAL = CSVWRITE('test.csv', 'select 1, 2')");
+        checkSqlWithDisabledFunction("DELETE FROM TEST WHERE VAL = SELECT count(*) FROM CSVREAD('test.csv')");
+        checkSqlWithDisabledFunction("DELETE FROM TEST WHERE VAL = MEMORY_FREE()");
+        checkSqlWithDisabledFunction("DELETE FROM TEST WHERE VAL = MEMORY_USED()");
+        checkSqlWithDisabledFunction("DELETE FROM TEST WHERE VAL = LOCK_MODE()");
+        checkSqlWithDisabledFunction("DELETE FROM TEST WHERE VAL = LINK_SCHEMA('TEST2', '', 'jdbc:h2:./test', 'sa', 'sa', 'PUBLIC')");
+        checkSqlWithDisabledFunction("DELETE FROM TEST WHERE VAL = SESSION_ID()");
+        checkSqlWithDisabledFunction("DELETE FROM TEST WHERE VAL = CANCEL_SESSION(1)");
+    }
+
+    /**
+     */
+    @Test
+    public void testAllowFunctionsDisabledByDefault() throws Exception {
+        setDisabledSqlFunction();
+
+        sql("SELECT FILE_WRITE(0, 'test.dat')").getAll();
+        sql("SELECT FILE_READ('test.dat')").getAll();
+        sql("SELECT CSVWRITE('test.csv', 'select 1, 2')").getAll();
+        sql("SELECT * FROM CSVREAD('test.csv')").getAll();
+        sql("SELECT MEMORY_FREE()").getAll();
+        sql("SELECT MEMORY_USED()").getAll();
+        sql("SELECT LOCK_MODE()").getAll();
+        sql("SELECT LINK_SCHEMA('TEST2', '', 'jdbc:h2:./test', 'sa', 'sa', 'PUBLIC')").getAll();
+        sql("SELECT SESSION_ID()").getAll();
+        sql("SELECT CANCEL_SESSION(1)").getAll();
+    }
+
+    /**
+     */
+    @Test
+    public void testCustomDisabledFunctionsSet_Length() throws Exception {
+        setDisabledSqlFunction("LENGTH");
+
+        sql("SELECT FILE_WRITE(0, 'test.dat')").getAll();
+        sql("SELECT FILE_READ('test.dat')").getAll();
+        sql("SELECT CSVWRITE('test.csv', 'select 1, 2')").getAll();
+        sql("SELECT * FROM CSVREAD('test.csv')").getAll();
+        sql("SELECT MEMORY_FREE()").getAll();
+        sql("SELECT MEMORY_USED()").getAll();
+        sql("SELECT LOCK_MODE()").getAll();
+        sql("SELECT LINK_SCHEMA('TEST2', '', 'jdbc:h2:./test', 'sa', 'sa', 'PUBLIC')").getAll();
+        sql("SELECT SESSION_ID()").getAll();
+        sql("SELECT CANCEL_SESSION(1)").getAll();
+
+        checkSqlWithDisabledFunction("SELECT LENGTH(?)", "test");
+    }
+
+    /**
+     */
+    @Test
+    public void testCustomDisabledFunctionsSet_FileRead_User() throws Exception {
+        setDisabledSqlFunction("FILE_READ", "USER");
+
+        sql("SELECT FILE_WRITE(0, 'test.dat')").getAll();
+        checkSqlWithDisabledFunction("SELECT FILE_READ('test.dat')");
+        sql("SELECT CSVWRITE('test.csv', 'select 1, 2')").getAll();
+        sql("SELECT * FROM CSVREAD('test.csv')").getAll();
+        sql("SELECT MEMORY_FREE()").getAll();
+        sql("SELECT MEMORY_USED()").getAll();
+        sql("SELECT LOCK_MODE()").getAll();
+        sql("SELECT LINK_SCHEMA('TEST2', '', 'jdbc:h2:./test', 'sa', 'sa', 'PUBLIC')").getAll();
+        sql("SELECT SESSION_ID()").getAll();
+        sql("SELECT CANCEL_SESSION(1)").getAll();
+
+        checkSqlWithDisabledFunction("SELECT USER()");
+
+        sql("SELECT CURRENT_TIMESTAMP()").getAll();
+    }
+
+    /**
+     */
+    private void checkSqlWithDisabledFunction(final String sql, final Object ... args) {
+        try {
+            sql(sql, args).getAll();
+
+            fail("Exception must be thrown");
+        }
+        catch (IgniteSQLException e) {
+            Matcher m = PTRN_FUNC_NOT_FOUND.matcher(e.getMessage());
+
+            assertTrue("Unexpected error message: " + e.getMessage(), m.find());
+        }
+        catch (Throwable e) {
+            log.error("Unexpected exception", e);
+
+            fail("Unexpected exception");
+        }
+    }
+
+    /**
+     * @param sql SQL query.
+     * @param args Query parameters.
+     * @return Results cursor.
+     */
+    private FieldsQueryCursor<List<?>> sql(String sql, Object ... args) {
+        IgniteEx ign = client ? grid("cli") :grid("srv");
+
+        return ign.context().query().querySqlFields(new SqlFieldsQuery(sql)
+            .setLocal(local)
+            .setArgs(args), false);
+    }
+
+    /**
+     * @param funcs Disabled SQL functions.
+     * @throws IgniteCheckedException On error.
+     */
+    private void setDisabledSqlFunction(String... funcs) throws IgniteCheckedException {
+        HashSet<String> set = new HashSet<>(Arrays.stream(funcs).collect(Collectors.toSet()));
+
+        ((IgniteH2Indexing)grid("srv").context().query().getIndexing())
+            .distributedConfiguration()
+            .disabledFunctions(set)
+            .get();
+    }
+}
diff --git a/modules/indexing/src/test/java/org/apache/ignite/testsuites/IgniteBinaryCacheQueryTestSuite2.java b/modules/indexing/src/test/java/org/apache/ignite/testsuites/IgniteBinaryCacheQueryTestSuite2.java
index c2aaabf1bcf5e..66ac052a5f1ff 100644
--- a/modules/indexing/src/test/java/org/apache/ignite/testsuites/IgniteBinaryCacheQueryTestSuite2.java
+++ b/modules/indexing/src/test/java/org/apache/ignite/testsuites/IgniteBinaryCacheQueryTestSuite2.java
@@ -49,6 +49,7 @@
 import org.apache.ignite.internal.processors.cache.query.ScanQueryOffheapExpiryPolicySelfTest;
 import org.apache.ignite.internal.processors.database.baseline.IgniteChangingBaselineCacheQueryNodeRestartSelfTest;
 import org.apache.ignite.internal.processors.database.baseline.IgniteStableBaselineCacheQueryNodeRestartsSelfTest;
+import org.apache.ignite.internal.processors.query.DisabledSqlFunctionsTest;
 import org.apache.ignite.internal.processors.query.DmlBatchSizeDeadlockTest;
 import org.apache.ignite.internal.processors.query.IgniteCacheGroupsCompareQueryTest;
 import org.apache.ignite.internal.processors.query.IgniteCacheGroupsSqlDistributedJoinSelfTest;
@@ -81,6 +82,8 @@
  */
 @RunWith(Suite.class)
 @Suite.SuiteClasses({
+    DisabledSqlFunctionsTest.class,
+
     SqlIndexConsistencyAfterInterruptAtomicCacheOperationTest.class,
     SqlIndexConsistencyAfterInterruptTxCacheOperationTest.class,
     SqlTwoCachesInGroupWithSameEntryTest.class,
diff --git a/modules/spring/src/test/java/org/apache/ignite/cache/store/spring/CacheSpringStoreSessionListenerSelfTest.java b/modules/spring/src/test/java/org/apache/ignite/cache/store/spring/CacheSpringStoreSessionListenerSelfTest.java
index 225ca80bc0a01..d3db02c9c3033 100644
--- a/modules/spring/src/test/java/org/apache/ignite/cache/store/spring/CacheSpringStoreSessionListenerSelfTest.java
+++ b/modules/spring/src/test/java/org/apache/ignite/cache/store/spring/CacheSpringStoreSessionListenerSelfTest.java
@@ -17,9 +17,12 @@
 
 package org.apache.ignite.cache.store.spring;
 
+import java.lang.reflect.Method;
 import java.sql.Connection;
 import java.sql.SQLException;
+import java.util.Collections;
 import java.util.Map;
+import java.util.Set;
 import javax.cache.Cache;
 import javax.cache.configuration.Factory;
 import javax.cache.integration.CacheLoaderException;
@@ -31,6 +34,8 @@
 import org.apache.ignite.cache.store.CacheStoreSessionListener;
 import org.apache.ignite.cache.store.CacheStoreSessionListenerAbstractSelfTest;
 import org.apache.ignite.cache.store.jdbc.CacheJdbcStoreSessionListener;
+import org.apache.ignite.internal.processors.query.h2.DistributedSqlConfiguration;
+import org.apache.ignite.internal.processors.query.h2.FunctionsManager;
 import org.apache.ignite.lang.IgniteBiInClosure;
 import org.apache.ignite.resources.CacheStoreSessionResource;
 import org.springframework.jdbc.core.JdbcTemplate;
@@ -45,6 +50,28 @@ public class CacheSpringStoreSessionListenerSelfTest extends CacheStoreSessionLi
     /** */
     private static final DataSource DATA_SRC = new DriverManagerDataSource(URL);
 
+    /** */
+    private static Method FunctionManager_removeFunctions;
+
+    /** {@inheritDoc} */
+    @Override protected void beforeTestsStarted() throws Exception {
+        super.beforeTestsStarted();
+
+        FunctionManager_removeFunctions = FunctionsManager.class.getDeclaredMethod("removeFunctions", Set.class);
+
+        FunctionManager_removeFunctions.setAccessible(true);
+
+        // Cleanup disabled functions because transaction manager uses LOCK_MODE()
+        FunctionManager_removeFunctions.invoke(FunctionsManager.class, Collections.emptySet());
+    }
+
+    /** {@inheritDoc} */
+    @Override protected void afterTestsStopped() throws Exception {
+        FunctionManager_removeFunctions.invoke(FunctionsManager.class, DistributedSqlConfiguration.DFLT_DISABLED_FUNCS);
+
+        super.afterTestsStopped();
+    }
+
     /** {@inheritDoc} */
     @Override protected Factory<? extends CacheStore<Integer, Integer>> storeFactory() {
         return new Factory<CacheStore<Integer, Integer>>() {
