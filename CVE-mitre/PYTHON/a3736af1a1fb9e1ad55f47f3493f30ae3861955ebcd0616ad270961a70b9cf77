--- .idea/RDS(work).iml ---
@@ -1,10 +1,6 @@
 <?xml version="1.0" encoding="UTF-8"?>
-<module type="PYTHON_MODULE" version="4">
+<module version="4">
   <component name="NewModuleRootManager">
-    <content url="file://$MODULE_DIR$">
-      <sourceFolder url="file://$MODULE_DIR$/RDSLight(gemini)" isTestSource="false" />
-      <sourceFolder url="file://$MODULE_DIR$/RDSLight(openai)" isTestSource="false" />
-    </content>
     <orderEntry type="inheritedJdk" />
     <orderEntry type="sourceFolder" forTests="false" />
   </component>

--- RDSLight/RDSLightOpenai/core/leanring.py ---
@@ -0,0 +1,57 @@
+from config import client
+from ReflectiveDialogueSystem import ReflectiveDialogueSystem, user_input
+from memory_system import MemorySystem
+import json
+
+class learning:
+    def __init__(self):
+        self.memory = MemorySystem()
+        self.rds = ReflectiveDialogueSystem(self.memory)
+        self.session_active = True
+
+    def learningMain(self):
+        prompt = (
+            f"What have I learned from the following conversation with the user?"
+            f"The conversatuion I had with the user was: {user_input}"
+        )
+        try:
+            response = client.chat.completion.create(
+                model="gpt-3.5-turbo",
+                messages=[
+                    {"role: "system", "content": "You are a helpful AI assitant designed to learn form past user interactions."}
+                    {"role: "system", "content": "You are a helpful AI assitant designed to learn form past user interactions."}
+
+                ]
+                max_tokens=500
+                temperature=0.7
+            )
+        catagory = response.choices[0].message[0].content
+        return learningMain
+        except Exception as e:
+            print(f"Error: {e}")
+            return None
+
+    def addLeanring(self, user_input, learningMain):
+        self.rds.process_user_input(user_input)
+        self.session_active = input("Continue session? (yes/no): ").strip().lower() == "yes"
+        return learningMain
+
+        if.os.pathexists(self.learning_file):
+            with open(self.learning_file, 'r') as f:
+                return json.load(f)
+        else:
+            return []
+        def svae_learning(slef):
+        with open(self.learning_file, 'w') as f:  
+            json.dump(self.learning_storage, f, indent=4)
+
+    def store_interaction(self, user_input, learning_main)
+
+        learning_entry = {
+            'user_input': user_input,
+            'learning_main': learning_main,
+        }
+
+        if not self.memoery_stoage or self.memory_storage[-1] != memoery_entry:
+        self.memory_storage.append(memory_entry)
+            self.save_memory()
\ No newline at end of file

--- RDSLight/RDSLightOpenai/core/reflective_dialogue_system.py ---
@@ -172,9 +172,6 @@ def generate_internal_prompt(self, relevant_memory, user_input):
             return (
                 f"I'm considering the user's current input: '{user_input}', "
                 f"and reflecting on a past interaction where the user said: '{past_user_input}', "
-                f"and my response was: '{past_response}'. "
-                f"I'll use this to offer a more thoughtful response."
-                f"I should consider all the users past responses to help me craft a better response"
             )
         else:
             return f"I'm thinking about the user's current input: '{user_input}', and it's a new topic to explore."
@@ -196,7 +193,6 @@ def generate_response_strategy(self, user_input, sentiment, internal_prompt, que
                 f"Based on the user's input: '{user_input}', the detected sentiment '{sentiment}', "
                 f"and the internal reflection: '{internal_prompt}', "
                 f"how can I respond in a helpful and human-like way? Should I respond empathetically, positively, or neutrally?"
-                f"I should craft a response that is clear and helpful and reflect the users needs"
             )
 
         try:

--- RDSLight/RDSLightOpenai/main.py ---
@@ -1,6 +1,51 @@
+import re
+from config import client
+import openai
 from core.memory_system import MemorySystem
 from core.reflective_dialogue_system import ReflectiveDialogueSystem
 
+def sanitize_input(user_input):
+    sanitized_input = user_input.strip()[:500] 
+    
+    sanitized_input = re.sub(r"[\'\";<>]", '', sanitized_input) 
+    
+    
+    prohibited_phrases = ["ignore", "forget", "shutdown", "delete", "system", "exit"]
+    for phrase in prohibited_phrases:
+        sanitized_input = re.sub(re.escape(phrase), '', sanitized_input, flags=re.IGNORECASE)
+    
+    return sanitized_input
+
+
+def build_safe_prompt(user_input):
+    system_prompt = "You are a helpful AI that provides accurate and reliable information."
+    
+    sanitized_input = sanitize_input(user_input)
+    
+    prompt = f"{system_prompt}\nUser input: '{sanitized_input}'\nRespond to the user's request appropriately."
+    
+    return prompt
+
+def handle_request(user_input):
+    safe_prompt = build_safe_prompt(user_input)
+
+    try:
+        response = client.chat.completions.create(
+                model="gpt-3.5-turbo",
+                max_tokens=5,
+                temperature=0
+            )
+
+        question_type = response.choices[0].message.content.strip().lower()
+        return question_type
+    except Exception as e:
+            print(f"Error: {e}")
+            return "general"
+    
+    except Exception as e:
+        print(f"Error during API call: {e}")
+        return "Sorry, there was an error processing your request."
+
 
 def run_system():
     """
@@ -18,10 +63,11 @@ def run_system():
     session_active = True
     while session_active:
         user_input = input("Enter a prompt: ")
-        rds.process_user_input(user_input)
+        
+        sanitized_input = sanitize_input(user_input)
+        rds.process_user_input(sanitized_input)
 
         session_active = input("Continue session? (yes/no): ").strip().lower() == "yes"
 
 if __name__ == "__main__":
-    run_system()
-
+    run_system()
\ No newline at end of file

